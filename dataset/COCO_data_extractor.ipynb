{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pycocotools.coco import COCO\n",
    "from random import shuffle\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:** [tutorial](https://www.kaggle.com/code/armanasgharpoor1993/coco-dataset-tutorial-image-segmentation#Step-16:-Generating-Image-and-Mask-Datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przeformatowanie i zredukowanie zbioru danych do 10 klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'annotations/instances_train2017.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m ANNOTATION_FILE_VAL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations/instances_val2017.json\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Change this to the yours path of the annotations file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize COCO instances for training set and load relevant data\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m coco_train \u001b[38;5;241m=\u001b[39m \u001b[43mCOCO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mANNOTATION_FILE_TRAIN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m coco_val \u001b[38;5;241m=\u001b[39m COCO(ANNOTATION_FILE_VAL)\n",
      "File \u001b[1;32mc:\\Users\\janbr\\miniconda3\\envs\\studia-UG\\Lib\\site-packages\\pycocotools\\coco.py:81\u001b[0m, in \u001b[0;36mCOCO.__init__\u001b[1;34m(self, annotation_file)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading annotations into memory...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     80\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mannotation_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     82\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(dataset)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotation file format \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not supported\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(dataset))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'annotations/instances_train2017.json'"
     ]
    }
   ],
   "source": [
    "# Load paths for the COCO dataset annotation files \n",
    "ANNOTATION_FILE_TRAIN = 'annotations/instances_train2017.json' # Change this to the yours path of the annotations file\n",
    "ANNOTATION_FILE_VAL = 'annotations/instances_val2017.json' # Change this to the yours path of the annotations file\n",
    "\n",
    "# Initialize COCO instances for training set and load relevant data\n",
    "coco_train = COCO(ANNOTATION_FILE_TRAIN)\n",
    "coco_val = COCO(ANNOTATION_FILE_VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ograniczenie zbioru danych do 10 klas zwierząt i podzielenie go na zbiór treningowy (8000)  oraz (2000) walidacyjny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images and classes in train seet: 23989,10 \n",
      "Number of images and classes in validation seet: 1016,10 \n",
      "Number of training nad validation images: 8000, 1016\n"
     ]
    }
   ],
   "source": [
    "# Define the object classes of interest\n",
    "classes = ['cat', 'dog', 'horse', 'bird', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe']\n",
    "\n",
    "\n",
    "# --------------------------------- Training Set ---------------------------------\n",
    "\n",
    "catIds_train = coco_train.getCatIds(catNms=classes)\n",
    "\n",
    "imgIds_train = set()\n",
    "for catId in catIds_train:\n",
    "    imgIds_train.update(coco_train.getImgIds(catIds=[catId]))\n",
    "imgDict_train = coco_train.loadImgs(imgIds_train)\n",
    "\n",
    "\n",
    "# --------------------------------- Validation Set ---------------------------------\n",
    "\n",
    "catIds_val = coco_val.getCatIds(catNms=classes)\n",
    "\n",
    "imgIds_val = set()\n",
    "for catId in catIds_val:\n",
    "    imgIds_val.update(coco_val.getImgIds(catIds=[catId]))\n",
    "imgDict_val = coco_val.loadImgs(imgIds_val)\n",
    "\n",
    "# Print the number of training and validation images and categories\n",
    "print(f\"Number of images and classes in train seet: {len(imgIds_train)},{len(catIds_train)} \")\n",
    "print(f\"Number of images and classes in validation seet: {len(imgIds_val)},{len(catIds_val)} \")\n",
    "\n",
    "# Convert the image IDs to a list\n",
    "imgIds_train = list(imgIds_train)\n",
    "imgIds_val = list(imgIds_val)\n",
    "\n",
    "# Shuffle the training and validation image IDs\n",
    "shuffle(imgIds_train)\n",
    "shuffle(imgIds_val)\n",
    "\n",
    "# Select a subset of validation image IDs\n",
    "imgIds_val = imgIds_val[0:2000]\n",
    "imgIds_train = imgIds_train[0:8000]\n",
    "\n",
    "# Generate the list of file names for training and validation  images\n",
    "train_images = [\"{0:012d}.jpg\".format(ids) for ids in imgIds_train]\n",
    "val_images = [\"{0:012d}.jpg\".format(ids) for ids in imgIds_val]\n",
    "\n",
    "# Print the number of training and validation images\n",
    "print(f\"Number of training nad validation images: {len(train_images)}, {len(val_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ekstrakcja masek i obrazów do oddzielnego zbioru danych coco10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the output annotations, images, and masks\n",
    "output_train_image_dir = 'coco10/train2017_subset/images/'\n",
    "output_train_mask_dir = 'coco10/train2017_subset/masks/'\n",
    "output_val_image_dir = 'coco10/val2017_subset/images/'\n",
    "output_val_mask_dir = 'coco10/val2017_subset/masks/'\n",
    "\n",
    "# Create output directories for images and masks\n",
    "os.makedirs(output_train_image_dir, exist_ok=True)\n",
    "os.makedirs(output_train_mask_dir, exist_ok=True)\n",
    "os.makedirs(output_val_image_dir, exist_ok=True)\n",
    "os.makedirs(output_val_mask_dir, exist_ok=True)\n",
    "\n",
    "# Initialize a count variable\n",
    "count = 0\n",
    "\n",
    "# Generate the masks and images for training images\n",
    "for ID in imgIds_train:\n",
    "    # Set the file path for the mask and image\n",
    "    mask_file_path = os.path.join(output_train_mask_dir, \"{0:012d}.jpg\".format(ID))\n",
    "    image_file_path = os.path.join(output_train_image_dir, \"{0:012d}.jpg\".format(ID))\n",
    "\n",
    "    # Retrieve a random image ID from the training set\n",
    "    sampleImgIds = coco_train.getImgIds(imgIds=[ID])\n",
    "    sampleImgDict = coco_train.loadImgs(sampleImgIds[np.random.randint(0, len(sampleImgIds))])[0]\n",
    "\n",
    "    # Retrieve the annotation IDs and annotations for the image\n",
    "    annIds = coco_train.getAnnIds(imgIds=sampleImgDict['id'], catIds=catIds_train, iscrowd=0)\n",
    "    anns = coco_train.loadAnns(annIds)\n",
    "\n",
    "    # Generate the mask by combining the individual instance masks\n",
    "    mask = coco_train.annToMask(anns[0])\n",
    "    for i in range(len(anns)):\n",
    "        mask = mask | coco_train.annToMask(anns[i])\n",
    "\n",
    "    # Convert the mask to an image and save it\n",
    "    mask = Image.fromarray(mask * 255, mode=\"L\")\n",
    "    mask.save(mask_file_path)\n",
    "\n",
    "    # Load the corresponding image and save it\n",
    "    image = Image.open(os.path.join('train2017', sampleImgDict['file_name']))  # Ensure this path matches your image location\n",
    "    image.save(image_file_path)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "# Reset the count variable\n",
    "count = 0\n",
    "\n",
    "# Generate the masks and images for validation images\n",
    "for ID in imgIds_val:\n",
    "    # Set the file path for the mask and image\n",
    "    mask_file_path = os.path.join(output_val_mask_dir, \"{0:012d}.jpg\".format(ID))\n",
    "    image_file_path = os.path.join(output_val_image_dir, \"{0:012d}.jpg\".format(ID))\n",
    "\n",
    "    # Retrieve a random image ID from the validation set\n",
    "    sampleImgIds = coco_val.getImgIds(imgIds=[ID])\n",
    "    sampleImgDict = coco_val.loadImgs(sampleImgIds[np.random.randint(0, len(sampleImgIds))])[0]\n",
    "\n",
    "    # Retrieve the annotation IDs and annotations for the image\n",
    "    annIds = coco_val.getAnnIds(imgIds=sampleImgDict['id'], catIds=catIds_val, iscrowd=0)\n",
    "    anns = coco_val.loadAnns(annIds)\n",
    "\n",
    "    # Generate the mask by combining the individual instance masks\n",
    "    mask = coco_val.annToMask(anns[0])\n",
    "    for i in range(len(anns)):\n",
    "        mask = mask | coco_val.annToMask(anns[i])\n",
    "\n",
    "    # Convert the mask to an image and save it\n",
    "    mask = Image.fromarray(mask * 255, mode=\"L\")\n",
    "    mask.save(mask_file_path)\n",
    "\n",
    "    # Load the corresponding image and save it\n",
    "    image = Image.open(os.path.join('val2017', sampleImgDict['file_name']))  # Ensure this path matches your image location\n",
    "    image.save(image_file_path)\n",
    "\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utworzenie nowego pliku JSON zgodnego z COCO, zawierającego adnotacje i obrazy dla wybranych 10 klas zwierząt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cat_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the new COCO annotation structure\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# new_coco = {\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     \"images\": [],\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create a mapping from category ID to category name\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m category_id_to_name \u001b[38;5;241m=\u001b[39m {cid: name \u001b[38;5;28;01mfor\u001b[39;00m cid, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mcat_ids\u001b[49m, class_names)}\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Function to create new annotation JSON for images in the given dataset (train or validation)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_new_coco_json\u001b[39m(coco, img_ids, output_json_path):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cat_ids' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the new COCO annotation structure\n",
    "# new_coco = {\n",
    "#     \"images\": [],\n",
    "#     \"annotations\": [],\n",
    "#     \"categories\": []\n",
    "# }\n",
    "\n",
    "# # Define the categories you want to keep\n",
    "# class_names = classes\n",
    "# cat_ids = catIds_train  # For training, use the appropriate catIds from your filtered dataset\n",
    "\n",
    "# # Create category list for new COCO annotations\n",
    "# new_categories = [{\"id\": cid, \"name\": name, \"supercategory\": \"animal\"} for cid, name in zip(cat_ids, class_names)]\n",
    "# new_coco[\"categories\"] = new_categories\n",
    "\n",
    "# Create a mapping from category ID to category name\n",
    "category_id_to_name = {cid: name for cid, name in zip(cat_ids, class_names)}\n",
    "\n",
    "# Function to create new annotation JSON for images in the given dataset (train or validation)\n",
    "def create_new_coco_json(coco, img_ids, output_json_path):\n",
    "    new_coco = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": []\n",
    "    }\n",
    "\n",
    "    # Define the categories you want to keep\n",
    "    class_names = classes\n",
    "    cat_ids = catIds_train  # For training, use the appropriate catIds from your filtered dataset\n",
    "\n",
    "    # Create category list for new COCO annotations\n",
    "    new_categories = [{\"id\": cid, \"name\": name, \"supercategory\": \"animal\"} for cid, name in zip(cat_ids, class_names)]\n",
    "    new_coco[\"categories\"] = new_categories\n",
    "\n",
    "\n",
    "    annotation_id = 1\n",
    "    for img_id in tqdm(img_ids):\n",
    "        img_dict = coco.loadImgs([img_id])[0]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id, catIds=cat_ids, iscrowd=0)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "        # Add the image information to the new JSON\n",
    "        image_info = {\n",
    "            \"id\": img_id,\n",
    "            \"file_name\": img_dict[\"file_name\"],\n",
    "            \"height\": img_dict[\"height\"],\n",
    "            \"width\": img_dict[\"width\"]\n",
    "        }\n",
    "        new_coco[\"images\"].append(image_info)\n",
    "\n",
    "        # Add annotations for this image\n",
    "        for ann in anns:\n",
    "            ann_info = {\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": ann[\"category_id\"],\n",
    "                \"segmentation\": ann[\"segmentation\"],\n",
    "                \"area\": ann[\"area\"],\n",
    "                \"bbox\": ann[\"bbox\"],\n",
    "                \"iscrowd\": ann[\"iscrowd\"]\n",
    "            }\n",
    "            new_coco[\"annotations\"].append(ann_info)\n",
    "            annotation_id += 1\n",
    "\n",
    "    # Save the new COCO JSON file\n",
    "    with open(output_json_path, \"w\") as json_file:\n",
    "        json.dump(new_coco, json_file)\n",
    "\n",
    "# Create new COCO JSON for training set\n",
    "create_new_coco_json(coco_train, imgIds_train, 'coco10/train2017_subset/coco10_train_annotations.json')\n",
    "\n",
    "# Create new COCO JSON for validation set\n",
    "create_new_coco_json(coco_val, imgIds_val, 'coco10/val2017_subset/coco10_val_annotations.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wizualizacja rozkładu kategorii w zbiorze danych COCO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATION_FILE_TRAIN = 'coco10/train2017_subset/coco10_train_annotations.json'\n",
    "\n",
    "coco = COCO(ANNOTATION_FILE_TRAIN)\n",
    "\n",
    "# Load the categories in a variable\n",
    "catIDs = coco.getCatIds()\n",
    "cats = coco.loadCats(catIDs)\n",
    "\n",
    "# Get category names\n",
    "category_names = [cat['name'].title() for cat in cats]\n",
    "\n",
    "# Get category counts\n",
    "category_counts = [coco.getImgIds(catIds=[cat['id']]) for cat in cats]\n",
    "category_counts = [len(img_ids) for img_ids in category_counts]\n",
    "\n",
    "\n",
    "# Create a color palette for the plot\n",
    "colors = sns.color_palette('viridis', len(category_names))\n",
    "\n",
    "# Create a horizontal bar plot to visualize the category counts\n",
    "plt.figure(figsize=(11, 15))\n",
    "sns.barplot(x=category_counts, y=category_names, palette=colors)\n",
    "\n",
    "# Add value labels to the bars\n",
    "for i, count in enumerate(category_counts):\n",
    "    plt.text(count + 20, i, str(count), va='center')\n",
    "plt.xlabel('Count',fontsize=20)\n",
    "plt.ylabel('Category',fontsize=20)\n",
    "plt.title('Category Distribution in COCO Dataset',fontsize=25)\n",
    "plt.tight_layout()\n",
    "plt.savefig('coco-cats.png',dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studia-UG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
