{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janbr\\Documents\\Repos\\DeepLearning\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import pytorch_lightning as pl\n",
    "import mlflow.pytorch\n",
    "import mlflow\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "from pathlib import Path\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "BASE_DIR = Path(os.getcwd()).resolve()  # <--- Changed to work in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    16: 0,  # bird\n",
    "    17: 1,  # cat\n",
    "    18: 2,  # dog\n",
    "    19: 3,  # horse\n",
    "    20: 4,  # sheep\n",
    "    21: 5,  # cow\n",
    "    22: 6,  # elephant\n",
    "    23: 7,  # bear\n",
    "    24: 8,  # zebra\n",
    "    25: 9   # giraffe\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCOCODataset(Dataset):\n",
    "    def __init__(self, image_dir, annotation, transforms=None):\n",
    "        self.image_dir = str(image_dir)\n",
    "        self.coco = COCO(annotation)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "        self.transforms = transforms\n",
    "        self.normalization=v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.ids[index]\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        path = self.coco.loadImgs(img_id)[0]['file_name']\n",
    "        img = Image.open(os.path.join(self.image_dir, path)).convert(\"RGB\")\n",
    "\n",
    "        masks = []\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in anns:\n",
    "            masks.append(self.coco.annToMask(ann))\n",
    "            x, y, w, h = ann['bbox']\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(category_mapping[ann['category_id']])\n",
    "\n",
    "        # If no annotations, create dummy\n",
    "        if len(boxes) == 0:\n",
    "            boxes = np.zeros((0, 4), dtype=np.float32)\n",
    "            labels = np.zeros((0,), dtype=np.int64)\n",
    "            masks = np.zeros((0, img.height, img.width), dtype=np.uint8)\n",
    "        else:\n",
    "            boxes = np.array(boxes, dtype=np.float32)\n",
    "            labels = np.array(labels, dtype=np.int64)\n",
    "            masks = np.stack(masks, axis=0).astype(np.uint8)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target[\"masks\"] = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        img = self.normalization(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=None, weights_backbone=ResNet50_Weights.IMAGENET1K_V1 )\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = torchvision.models.detection.mask_rcnn.MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskRCNNLightningModule(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, images, targets=None):\n",
    "        return self.model(images, targets)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        images = list(img.to(self.device) for img in images)\n",
    "        targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n",
    "        # self.model.train()\n",
    "        loss_dict = self.model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        self.log('train_loss', losses)\n",
    "        return losses\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        images = list(img.to(self.device) for img in images)\n",
    "        targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n",
    "        self.model.train()\n",
    "        loss_dict = self.model(images, targets)\n",
    "\n",
    "        if not isinstance(loss_dict, dict):\n",
    "            raise TypeError(f\"Unexpected type for loss_dict: {type(loss_dict)}\")\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        self.log('val_loss', losses, prog_bar=True, logger=True)\n",
    "        return losses\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "        return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension of the callback class (Lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricTracker(pl.Callback):\n",
    "    def __init__(self):\n",
    "        self.collection = []\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "        if \"val_loss\" in outputs:\n",
    "            vacc = outputs[\"val_loss\"]\n",
    "            self.collection.append(vacc)\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        if \"val_loss\" in trainer.logged_metrics:\n",
    "            elogs = trainer.logged_metrics[\"val_loss\"]\n",
    "            self.collection.append(elogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training (with Pytorch Lightning Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.63s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Could not find experiment with ID 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# metric_tracker = MetricTracker()\u001b[39;00m\n\u001b[0;32m     23\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m     24\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     25\u001b[0m     logger\u001b[38;5;241m=\u001b[39mmlf_logger,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# callbacks=[metric_tracker]\u001b[39;00m\n\u001b[0;32m     27\u001b[0m )\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     30\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mfit(module, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_loader, val_dataloaders\u001b[38;5;241m=\u001b[39mval_loader)\n\u001b[0;32m     31\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mpytorch\u001b[38;5;241m.\u001b[39mlog_model(module\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\janbr\\miniconda3\\envs\\studia-UG\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:446\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[0m\n\u001b[0;32m    442\u001b[0m         user_specified_tags[MLFLOW_RUN_NAME] \u001b[38;5;241m=\u001b[39m run_name\n\u001b[0;32m    444\u001b[0m     resolved_tags \u001b[38;5;241m=\u001b[39m context_registry\u001b[38;5;241m.\u001b[39mresolve_tags(user_specified_tags)\n\u001b[1;32m--> 446\u001b[0m     active_run_obj \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_id_for_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log_system_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# If `log_system_metrics` is not specified, we will check environment variable.\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     log_system_metrics \u001b[38;5;241m=\u001b[39m MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[1;32mc:\\Users\\janbr\\miniconda3\\envs\\studia-UG\\Lib\\site-packages\\mlflow\\tracking\\client.py:393\u001b[0m, in \u001b[0;36mMlflowClient.create_run\u001b[1;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_run\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     experiment_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    344\u001b[0m     run_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    345\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Run:\n\u001b[0;32m    346\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;124;03m    Create a :py:class:`mlflow.entities.Run` object that can be associated with\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    metrics, parameters, artifacts, etc.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m        status: RUNNING\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janbr\\miniconda3\\envs\\studia-UG\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:169\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_run\u001b[1;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# Extract user from tags\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# This logic is temporary; the user_id attribute of runs is deprecated and will be removed\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# in a later release.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m user_id \u001b[38;5;241m=\u001b[39m tags\u001b[38;5;241m.\u001b[39mget(MLFLOW_USER, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mRunTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janbr\\miniconda3\\envs\\studia-UG\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:639\u001b[0m, in \u001b[0;36mFileStore.create_run\u001b[1;34m(self, experiment_id, user_id, start_time, tags, run_name)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03mCreates a run with the specified attributes.\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    638\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m FileStore\u001b[38;5;241m.\u001b[39mDEFAULT_EXPERIMENT_ID \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[1;32m--> 639\u001b[0m experiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not create run under experiment with ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - no such \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    643\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    644\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST,\n\u001b[0;32m    645\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\janbr\\miniconda3\\envs\\studia-UG\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:448\u001b[0m, in \u001b[0;36mFileStore.get_experiment\u001b[1;34m(self, experiment_id)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mFetch the experiment.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03mNote: This API will search for active as well as deleted experiments.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;124;03m    A single Experiment object if it exists, otherwise raises an Exception.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    447\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m FileStore\u001b[38;5;241m.\u001b[39mDEFAULT_EXPERIMENT_ID \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[1;32m--> 448\u001b[0m experiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    452\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST,\n\u001b[0;32m    453\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\janbr\\miniconda3\\envs\\studia-UG\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:418\u001b[0m, in \u001b[0;36mFileStore._get_experiment\u001b[1;34m(self, experiment_id, view_type)\u001b[0m\n\u001b[0;32m    416\u001b[0m experiment_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_experiment_path(experiment_id, view_type)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find experiment with ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    420\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST,\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m meta \u001b[38;5;241m=\u001b[39m FileStore\u001b[38;5;241m.\u001b[39m_read_yaml(experiment_dir, FileStore\u001b[38;5;241m.\u001b[39mMETA_DATA_FILE_NAME)\n\u001b[0;32m    423\u001b[0m meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_experiment_tags(experiment_id)\n",
      "\u001b[1;31mMlflowException\u001b[0m: Could not find experiment with ID 0"
     ]
    }
   ],
   "source": [
    "num_classes = 11  # Example: 1 class (background) + 1 class (object)\n",
    "train_images_dir = BASE_DIR / \"dataset/coco10/train2017_subset/images\"\n",
    "train_ann_dir = BASE_DIR / \"dataset/coco10/train2017_subset/coco10_train_annotations.json\"\n",
    "val_images_dir = BASE_DIR / \"dataset/coco10/val2017_subset/images\"\n",
    "val_ann_dir = BASE_DIR / \"dataset/coco10/val2017_subset/coco10_val_annotations.json\"\n",
    "train_dataset = CustomCOCODataset(image_dir=train_images_dir, annotation=train_ann_dir, transforms=T.ToTensor())\n",
    "val_dataset = CustomCOCODataset(image_dir=val_images_dir, annotation=val_ann_dir, transforms=T.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "model = build_model(num_classes=num_classes)\n",
    "module = MaskRCNNLightningModule(model=model)\n",
    "\n",
    "mlf_logger = MLFlowLogger(\n",
    "    experiment_name=f\"maskrcnn_resnet\",\n",
    "    tracking_uri=\"http://localhost:5000\",\n",
    "    log_model=True,\n",
    ")\n",
    "mlflow.set_experiment(\"maskrcnn_resnet\") # Żeby eksperyment był widoczny w MLFlow\n",
    "\n",
    "\n",
    "# metric_tracker = MetricTracker()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    logger=mlf_logger,\n",
    "    # callbacks=[metric_tracker]\n",
    ")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    trainer.fit(module, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "    mlflow.pytorch.log_model(module.model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaskRCNNPredictor(\n",
      "  (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (mask_fcn_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "# Wartości testowe\n",
    "in_channels = 256\n",
    "hidden_layer = 256\n",
    "num_classes = 3\n",
    "\n",
    "# Test inicjalizacji\n",
    "predictor = MaskRCNNPredictor(in_channels, hidden_layer, num_classes)\n",
    "print(predictor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studia-UG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
