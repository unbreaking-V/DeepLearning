{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models import detection\n",
    "import lightning as pl\n",
    "import os\n",
    "os.chdir(\"/home/matrament/studia/deep_learning/DeepLearning\")\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "# visualisation\n",
    "import torchvision\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from torchvision import transforms as T\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, annotation_dir, transforms=None):\n",
    "        # self.transform =  v2.Compose([\n",
    "        #     v2.ToImage(),\n",
    "        #     v2.RandomResizedCrop(size=(100, 100), antialias=True),\n",
    "        #     v2.RandomHorizontalFlip(p=0.5),\n",
    "        #     v2.ToDtype(torch.float32, scale=True),\n",
    "        # ])     \n",
    "        # self.normalization=v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.transforms = transforms\n",
    "        self.image_dir = image_dir\n",
    "        self.coco = COCO(annotation_dir)\n",
    "        self.cat_ids = self.coco.getCatIds()\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_id = self.coco.getImgIds()[idx]\n",
    "\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id, catIds=self.cat_ids, iscrowd=None)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        img = self.coco[idx][0]\n",
    "        # Bounding boxes for objects\n",
    "        # In coco format, bbox = [xmin, ymin, width, height]\n",
    "        # In maskrcnn, the input should be [xmin, ymin, xmax, ymax]\n",
    "        # Prepare target dictionary\n",
    "        boxes = []\n",
    "        masks = []\n",
    "        labels = []\n",
    "        areas = []\n",
    "        iscrowd = []\n",
    "\n",
    "        for ann in anns:\n",
    "            # Bounding box\n",
    "            x, y, w, h = ann['bbox']\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "\n",
    "            # Segmentation mask\n",
    "            mask = self.coco.annToMask(ann)\n",
    "            masks.append(mask)\n",
    "\n",
    "            # Category ID\n",
    "            labels.append(ann['category_id'])\n",
    "\n",
    "            # Area and iscrowd\n",
    "            areas.append(ann['area'])\n",
    "            iscrowd.append(ann.get('iscrowd', 0))\n",
    "\n",
    "        # Convert to tensors\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
    "\n",
    "        # Target dictionary\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"masks\": masks,\n",
    "            \"image_id\": torch.tensor([img_id]),\n",
    "            \"area\": areas,\n",
    "            \"iscrowd\": iscrowd,\n",
    "        }\n",
    "\n",
    "        # Apply transforms if provided\n",
    "        if self.transforms:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.82s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_train=CocoDataset(\"dataset/train2017_subset\", \"dataset/instances_train2017_subset.json\",get_transform(train=True)) # define the dataset\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=16, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=None)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = torchvision.models.detection.mask_rcnn.MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(dataset_train.coco.cats) +1 # 1 for background\n",
    "model = build_model(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskRCNNLitModule(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=0.005):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        loss_dict = self.model(images, targets)\n",
    "        total_loss = sum(loss for loss in loss_dict.values())\n",
    "        self.log(\"train_loss\", total_loss)\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        loss_dict = self.model(images, targets)\n",
    "        total_loss = sum(loss for loss in loss_dict.values())\n",
    "        self.log(\"val_loss\", total_loss)\n",
    "        return total_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "            momentum=0.9,\n",
    "            weight_decay=0.0005\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, images, targets):\n",
    "        return self.model(images, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension of the callback class (Lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricTracker(pl.Callback): # extend the Callback class\n",
    "\n",
    "    def __init__(self):\n",
    "        self.collection = []\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        vacc = outputs[\"val_loss\"]  # you can access them here\n",
    "        self.collection.append(vacc)  # track them\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, module):\n",
    "        elogs = trainer.logged_metrics[\"val_loss\"]  # access it here\n",
    "        self.collection.append(elogs)\n",
    "        # do whatever is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MlFlow Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_logger = MLFlowLogger(\n",
    "            experiment_name=f\"maskrcnn_resnet\",\n",
    "            tracking_uri=\"http://localhost:5000\",\n",
    "            log_model=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training (with Pytorch Lightning Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metr = MetricTracker()\n",
    "litmodule = MaskRCNNLitModule(model)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    enable_progress_bar=True,\n",
    "    logger=mlf_logger,\n",
    "    default_root_dir=f\"/tmp/{'v'}_{74}\",\n",
    "    callbacks=[\n",
    "        metr,\n",
    "    ],\n",
    ")\n",
    "trainer.fit(\n",
    "            model=litmodule, train_dataloaders=train_loader #, val_dataloaders=val_loader\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
